# Setting up local llm inference using vLLM


